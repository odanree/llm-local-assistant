# v2.6 Voice Narration - File Structure Overview

## Current Project Structure

```
llm-local-assistant/
├── src/                          # TypeScript source (extension)
│   ├── extension.ts              # Main entry point
│   ├── commands/                 # Command handlers (TODO: create for v2.6)
│   ├── services/                 # Services layer
│   │   ├── index.ts
│   │   ├── smartValidator.ts
│   │   ├── semanticValidator.ts
│   │   ├── ValidatorProfiles.ts
│   │   ├── PromptEngine.ts
│   │   └── DomainAwareAuditor.ts
│   ├── types/                    # TypeScript interfaces
│   │   ├── index.ts
│   │   ├── executor.ts
│   │   └── validation.ts
│   ├── utils/                    # Utility functions
│   │   ├── contextBuilder.ts
│   │   ├── diffGenerator.ts
│   │   ├── pathSanitizer.ts
│   │   ├── workspaceDetector.ts
│   │   └── ... (15+ more)
│   ├── validators/               # Validation logic
│   │   └── architectureValidator.ts
│   ├── *.ts                      # Individual modules
│   │   ├── llmClient.ts
│   │   ├── planner.ts
│   │   ├── executor.ts
│   │   ├── refiner.ts
│   │   ├── patternDetector.ts
│   │   └── ... (50+ more)
│   └── *.test.ts                 # Test files (co-located)
│
├── python/                        # Python code (TODO: create for v2.6)
│   ├── tts_service.py            # NEW: ChatTTS service wrapper
│   ├── setup_tts.py              # NEW: Setup/download script
│   └── test_tts.py               # NEW: Test utilities
│
├── webview/                       # React webview (TODO: create for v2.6)
│   ├── components/               # NEW: React components
│   │   ├── AudioPlayer.tsx       # NEW: Audio player widget
│   │   └── index.ts
│   ├── panels/                   # NEW: Panel components
│   │   ├── ExplanationPanel.tsx  # NEW: Modified explanation panel
│   │   └── index.ts
│   ├── styles/                   # NEW: CSS styles
│   │   ├── audioPlayer.css       # NEW: Audio player styles
│   │   └── index.css
│   ├── index.html                # Main webview HTML
│   └── index.ts                  # Webview entry point
│
├── docs/                          # Documentation
│   ├── VOICE_NARRATION.md        # NEW: Setup & usage guide
│   └── ... (other docs)
│
├── V2.6_VOICE_NARRATION_PLAN.md  # Implementation plan (NEW)
├── package.json                   # Extension manifest + config
├── tsconfig.json
├── webpack.config.js
├── vitest.config.ts
├── .gitignore
└── ... (other config files)
```

---

## Where v2.6 Code Lives

### NEW DIRECTORIES

#### 1. `python/` - TTS Model & Service (NEW)

**Purpose:** ChatTTS model management and synthesis

```
python/
├── tts_service.py
│   - ChatTTSService class
│   - synthesize() method
│   - numpy_to_wav() converter
│   - CLI interface
│   - Subprocess integration
│
├── setup_tts.py
│   - Download ChatTTS model (~1GB)
│   - Install dependencies
│   - Cache model for first run
│   - Error handling
│
└── test_tts.py
    - Quick test script
    - Generates test_audio.wav
    - Verifies setup
```

**Why separate from src/?**
- Python is a different runtime (not bundled with VS Code extension)
- Runs as subprocess (isolated)
- Can be updated independently
- Users can run setup separately
- Easy to swap TTS models later

---

#### 2. `src/services/ttsService.ts` (NEW)

**Purpose:** Node.js bridge to Python TTS

```typescript
src/services/
├── ttsService.ts (NEW)
│   - TTSService class
│   - synthesize(options: TTSOptions)
│   - getDeviceInfo()
│   - _synthesizeChunk()
│   - _synthesizeChunked()
│   - _splitText() (sentence boundaries)
│   - Subprocess spawning
│   - Audio buffer handling
│
├── index.ts (MODIFIED)
│   - Export ttsService
│
└── ... (existing services)
```

**Why in services/?**
- Follows existing pattern (SmartValidator, PromptEngine, etc.)
- Singleton instance shared across commands
- Clean API for commands to call
- Testable in isolation

---

#### 3. `src/commands/explain.ts` (NEW - or modify existing)

**Purpose:** Integrate voice narration with `/explain` command

**Current structure:** Commands are likely in `extension.ts` or scattered  
**v2.6 change:** Create dedicated command file

```typescript
src/commands/
├── index.ts
│   - Register all commands
│   - /explain
│   - /refactor
│   - /rate-architecture
│   - /setup-voice (NEW)
│   - /test-voice (NEW)
│
└── explain.ts (NEW or MODIFIED)
    - explainCommand() function
    - Call ttsService.synthesize()
    - Handle audio file saving
    - Return to webview with audio path
```

**Integration point:**
```typescript
// In explain.ts
const audioResult = await ttsService.synthesize({
  text: explanation,
  lang: 'en',
  maxChunkLength: 500
});

// Save audio to workspace cache
const audioPath = path.join(workspaceRoot, '.llm-cache/audio/explain-*.wav');
fs.writeFileSync(audioPath, audioResult.audioBuffer);

// Send to webview with audio metadata
panel.webview.postMessage({
  command: 'showExplanation',
  text: explanation,
  audio: {
    path: audioPath,
    sampleRate: audioResult.sampleRate,
    duration: audioResult.duration
  }
});
```

---

#### 4. `src/types/tts.ts` (NEW)

**Purpose:** TypeScript interfaces for TTS

```typescript
src/types/
├── tts.ts (NEW)
│   - TTSOptions interface
│   - TTSResult interface
│   - DeviceInfo interface
│   - AudioMetadata interface
│
├── index.ts (MODIFIED)
│   - Export types/tts
│
└── ... (existing types)
```

**Interfaces:**
```typescript
export interface TTSOptions {
  text: string;
  lang?: 'en' | 'zh';
  maxChunkLength?: number;
  device?: 'auto' | 'cuda' | 'cpu';
}

export interface TTSResult {
  audioBuffer: Buffer;
  sampleRate: number;
  duration: number;
}
```

---

#### 5. `webview/components/AudioPlayer.tsx` (NEW)

**Purpose:** React audio player widget

```
webview/
├── components/
│   ├── AudioPlayer.tsx (NEW)
│   │   - Play/Pause button
│   │   - Progress bar with seek
│   │   - Speed selector (0.75x - 2x)
│   │   - Volume slider
│   │   - Time display
│   │   - Keyboard shortcuts
│   │   - ARIA labels
│   │   - Dark mode support
│   │
│   └── index.ts (MODIFIED)
│       - Export AudioPlayer
│
└── ... (existing components)
```

---

#### 6. `webview/panels/ExplanationPanel.tsx` (MODIFIED)

**Purpose:** Show explanation + audio player together

**Current state:** Likely shows just text  
**v2.6 change:** Add audio player above text

```typescript
webview/panels/
├── ExplanationPanel.tsx (MODIFIED)
│   - Receive audio metadata from command
│   - Show AudioPlayer if audio exists
│   - Show explanation text
│   - Show error if audio failed
│
└── ... (existing panels)
```

**Integration:**
```typescript
<ExplanationPanel
  text={explanation}
  audio={{
    path: audioPath,
    sampleRate: 24000,
    duration: 5.2
  }}
/>
```

---

#### 7. `webview/styles/audioPlayer.css` (NEW)

**Purpose:** Styles for audio player

```
webview/styles/
├── audioPlayer.css (NEW)
│   - .audio-player container
│   - .player-controls
│   - .control-btn (play/pause)
│   - .progress-bar
│   - .speed-controls
│   - .volume-control
│   - .time-display
│   - Dark mode media queries
│   - Accessibility focus states
│
└── index.css (MODIFIED)
    - Import audioPlayer.css
```

---

#### 8. `docs/VOICE_NARRATION.md` (NEW)

**Purpose:** User-facing documentation

```
docs/
├── VOICE_NARRATION.md (NEW)
│   - Overview
│   - Installation (setup command)
│   - Configuration options
│   - Usage examples
│   - Performance notes
│   - Troubleshooting
│   - FAQ
│
└── ... (existing docs)
```

---

### MODIFIED FILES

#### `src/extension.ts` (MODIFIED)

```typescript
// Add to registerCommands()
vscode.commands.registerCommand('llm-assistant.setup-voice', setupVoiceCommand);
vscode.commands.registerCommand('llm-assistant.test-voice', testVoiceCommand);

// Add to explainCommand handler
const audioResult = await ttsService.synthesize({...});
```

---

#### `package.json` (MODIFIED)

```json
{
  "contributes": {
    "configuration": {
      "properties": {
        "llm-assistant.voice.enabled": {...},
        "llm-assistant.voice.speed": {...},
        "llm-assistant.voice.language": {...},
        "llm-assistant.voice.maxChunkLength": {...}
      }
    },
    "commands": [
      {
        "command": "llm-assistant.setup-voice",
        "title": "LLM: Setup Voice Narration"
      },
      {
        "command": "llm-assistant.test-voice",
        "title": "LLM: Test Voice Narration"
      }
    ]
  }
}
```

---

#### `tsconfig.json` (NO CHANGE)

- Already handles `src/**/*.ts`
- No webview compilation needed (exists already)
- Python files not TypeScript, so ignored

---

#### `webpack.config.js` (MODIFIED - maybe)

**Only if packaging webview separately:**
```javascript
// May need to add:
module: {
  rules: [
    {
      test: /\.css$/,
      use: ['style-loader', 'css-loader']
    }
  ]
}
```

*Usually not needed—webview CSS already handled*

---

### BUILD & CACHE STRUCTURE

#### `.llm-cache/audio/` (NEW - runtime)

Generated when running `/explain`:

```
.llm-cache/
└── audio/
    ├── explain-1707561234567.wav
    ├── explain-1707561245892.wav
    └── explain-1707561256123.wav
```

**Why cache?**
- Avoid re-synthesizing same text
- Store for quick playback
- Can be cleared without affecting functionality
- Added to `.gitignore`

---

## File Count Summary

| Category | Count | Location |
|----------|-------|----------|
| Python TTS | 3 | `python/` |
| TypeScript (Services) | 1 | `src/services/` |
| TypeScript (Commands) | 1 | `src/commands/` |
| TypeScript (Types) | 1 | `src/types/` |
| React Components | 2 | `webview/components/`, `webview/panels/` |
| CSS Styles | 1 | `webview/styles/` |
| Documentation | 1 | `docs/` |
| Plan Document | 1 | Root |
| **TOTAL NEW** | **11** | Various |
| **MODIFIED** | 4-5 | `src/extension.ts`, `package.json`, etc. |

---

## Dependency Flow

```
User runs: /explain

↓

extension.ts
  - Command handler
  - Calls explainCommand()

↓

src/commands/explain.ts
  - Generate explanation text
  - Check settings (voice enabled?)
  - Call ttsService.synthesize()

↓

src/services/ttsService.ts
  - Split text at sentence boundaries
  - Spawn Python subprocess

↓

python/tts_service.py
  - Load ChatTTS model (if not cached)
  - Call model.infer()
  - Convert to WAV bytes
  - Write to stdout

↓

ttsService.ts receives audio buffer
  - Save to .llm-cache/audio/
  - Return TTSResult

↓

extension.ts sends webview message
  - Text: explanation
  - Audio: { path, sampleRate, duration }

↓

webview/panels/ExplanationPanel.tsx
  - Renders AudioPlayer + text
  - User clicks Play
  - HTML5 Audio API plays file
```

---

## Setup Checklist for v2.6

- [ ] Create `python/` directory with 3 files
- [ ] Create `src/services/ttsService.ts`
- [ ] Create `src/types/tts.ts`
- [ ] Create `src/commands/` directory (if doesn't exist)
- [ ] Create `src/commands/explain.ts` (or modify existing)
- [ ] Create `webview/components/AudioPlayer.tsx`
- [ ] Modify `webview/panels/ExplanationPanel.tsx`
- [ ] Create `webview/styles/audioPlayer.css`
- [ ] Create `docs/VOICE_NARRATION.md`
- [ ] Modify `src/extension.ts` (register commands)
- [ ] Modify `package.json` (settings + commands)
- [ ] Update `webview/styles/index.css` (import audioPlayer.css)
- [ ] Add `.llm-cache/` to `.gitignore`
- [ ] Test: `npm run compile`
- [ ] Test: `/setup-voice` command
- [ ] Test: `/explain` with audio

---

## Code Organization Principles

**Following existing patterns:**

1. **Services layer** - Singleton, shared across commands (✅ ttsService.ts)
2. **Types in `types/`** - All interfaces together (✅ tts.ts)
3. **Utils for helpers** - Reusable functions (✅ diffGenerator, contextBuilder)
4. **Commands in `extension.ts` or `commands/`** - Single entry point (✅ explain.ts)
5. **Webview in `webview/`** - React components separated (✅ AudioPlayer, ExplanationPanel)
6. **Tests co-located** - Same directory as source (✅ *.test.ts)
7. **Docs in `docs/`** - User-facing markdown (✅ VOICE_NARRATION.md)

**No breaking changes to existing code** - All new, nothing removed.

---

## Install Requirements for v2.6

**Before users can use voice narration:**

1. **Python 3.8+** (must exist)
   ```bash
   python --version
   ```

2. **Dependencies** (installed by setup command)
   ```bash
   pip install ChatTTS numpy torch torchaudio
   ```

3. **Model download** (~1GB, first run only)
   - Automatic when running `/setup-voice`
   - Or on first `/explain` if not cached

**No npm dependencies added** - Python runs separately.

---

## Ready to Code?

This structure means:

✅ Minimal changes to existing code  
✅ Clean separation of concerns  
✅ Python and Node.js isolated  
✅ Easy to test each layer  
✅ Easy to swap TTS models later  
✅ Easy to add voice cloning (v2.7)  

Start with Phase 1: Create `python/` directory and TTS service files.
